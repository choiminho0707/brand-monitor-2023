import requests
from bs4 import BeautifulSoup
import pandas as pd
import random
import time
import re # ì •ê·œí‘œí˜„ì‹ ëª¨ë“ˆ ì¶”ê°€

def scrape_reviews_only():
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    
    base_urls = {
        "Products": "https://web-scraping.dev/products",
        "Testimonials": "https://web-scraping.dev/testimonials",
        "Reviews": "https://web-scraping.dev/reviews"
    }
    
    all_raw_data = []
    
    for category, url in base_urls.items():
        print(f"ğŸš€ {category} ì„¹ì…˜ì—ì„œ ë¶„ì„ ì†ŒìŠ¤ ìˆ˜ì§‘ ì¤‘...")
        for page in range(1, 11): 
            try:
                res = requests.get(f"{url}?page={page}", headers=headers, timeout=10)
                if res.status_code != 200: break
                
                soup = BeautifulSoup(res.text, 'html.parser')
                items = soup.select('.review, .testimonial, .product, .card-body, p, blockquote')
                
                page_count = 0
                for item in items:
                    text = item.get_text(separator=' ', strip=True)
                    
                    # [í•µì‹¬ ìˆ˜ì •] ë¬¸ì¥ ëì— ë¶™ì€ ê°€ê²©(ì˜ˆ: 24.99) ì œê±° ì •ê·œí‘œí˜„ì‹
                    # \s? : ê³µë°±ì´ ìˆì„ìˆ˜ë„ ì—†ì„ìˆ˜ë„ ìˆìŒ
                    # \d+ : ìˆ«ì í•˜ë‚˜ ì´ìƒ
                    # \. : ë§ˆì¹¨í‘œ
                    # \d{2} : ìˆ«ì ì •í™•íˆ 2ìë¦¬
                    # $ : ë¬¸ì¥ì˜ ëì„ ì˜ë¯¸
                    text = re.sub(r'\s?\d+\.\d{2}$', '', text)
                    
                    if len(text) > 30: 
                        all_raw_data.append(text)
                        page_count += 1
                
                if page_count == 0: break 
                time.sleep(0.05)
            except: break

    unique_texts = list(set(all_raw_data))
    final_rows = []
    
    for i, text in enumerate(unique_texts):
        month = (i % 12) + 1
        day = random.randint(1, 28)
        
        final_rows.append({
            "Category": "Reviews",
            "Title": f"Customer Feedback #{i+1}",
            "Text": text,
            "Date": f"2023-{month:02d}-{day:02d}"
        })

    df = pd.DataFrame(final_rows)
    df.to_csv("reviews.csv", index=False, encoding='utf-8-sig')
    print(f"âœ… ê°€ê²© ì •ë³´ê°€ ì œê±°ëœ {len(df)}ê°œì˜ ë°ì´í„°ê°€ 'reviews.csv'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    scrape_reviews_only()